Ja, Metapher passt ziemlich gut: **K√∂rper = lauff√§hige Infrastruktur**, **Seele = Sheratan-Semantik** (Schema/Policy/Routing/Trace/Recovery). Und ja: die ‚ÄúSeele‚Äù kann leichtgewichtig bleiben, wenn der K√∂rper stabil ist.

Jetzt zu deiner eigentlichen Frage:

## 1) Werden viele Pakete speicherlastig?

**Kommt drauf an, wo ‚Äúspeicherlastig‚Äù gemeint ist:**

* **Disk (Installgr√∂√üe / EXE-Bundle):** ja, kann schnell aufblasen. Vor allem bei:

  * PyInstaller (packt Python-Runtime + libs + evtl. ganze Dependency-B√§ume)
  * ML/LLM-Stacks (numpy/scipy/torch etc.)
  * UI + Node_modules (nur im Build-Workspace; im Release sind‚Äôs ‚Äúdist‚Äù Files)

* **RAM zur Laufzeit:** meist **viel weniger** als man denkt. Viele Pakete liegen nur auf Disk, werden aber nicht importiert/geladen, solange du sie nicht nutzt (Ausnahmen: heavy imports).

Kurz: **Die Hauptstrafe ist fast immer Disk/Bundle-Gr√∂√üe, nicht RAM.**

---

## 2) Gibt es ein Tool, das ‚Äúalles startet, jede Funktion nutzt‚Äù und dann den minimalen Rest extrahiert?

F√ºr **JavaScript/Frontend**: sowas existiert *relativ gut* (Tree-Shaking durch Vite/Rollup/Webpack), weil Imports statischer sind.

F√ºr **Python**: **nein, nicht zuverl√§ssig als ‚Äúvollautomatisches Extrahieren‚Äù** ‚Äì aus einem simplen Grund:

* Python hat **dynamische Imports**, Plugins, Reflection, optionale Pfade, `importlib`, ‚Äúoptional dependencies‚Äù, Runtime-Branching, etc.
* Das hei√üt: ‚ÄúWelche Teile werden wirklich gebraucht?‚Äù ist nicht entscheidbar, ohne **deinen** Nutzungsraum exakt zu kennen. Ein Tool kann nur raten.

Es gibt aber **brauchbare N√§herungen**, die in der Praxis genau das Ziel treffen: *sehr klein werden, ohne Funktion zu verlieren*.

---

## 3) Was es stattdessen gibt (realistische Werkzeuge)

### A) ‚ÄúMinimaler Bundle-Graph‚Äù (praktisch)

**PyInstaller** kann:

* ein Import-Dependency-Graph erstellen
* unn√∂tige Module ausschlie√üen (`--exclude-module`)
* nicht ben√∂tigte ‚Äúhooks‚Äù vermeiden
* ‚Äúhiddenimports‚Äù kontrollieren

‚û°Ô∏è Das ist kein ‚Äúrein extrahieren‚Äù, aber ein **kontrolliertes Schrumpfen**.

### B) ‚ÄúBuild-Trimming‚Äù (sehr effektiv)

* **UPX** komprimiert viele Binary-Teile (nicht immer kompatibel, aber oft effektiv).
* `strip` / debug symbols entfernen (plattformabh√§ngig).
* Wheels bevorzugen (keine Build-Artefakte im Release).

### C) ‚ÄúFreeze/Compile statt Bundle‚Äù

Tools wie **Nuitka** (Python‚ÜíC‚ÜíBinary) k√∂nnen oft:

* kleinere Deployments liefern
* aggressiver optimieren

Tradeoff: Build-Komplexit√§t.

### D) Dependency-Management, damit du gar nicht erst M√ºll installierst

* `pip-tools` / `poetry` (lockfiles, reproduzierbar)
* Extras sauber trennen: `pip install sheratan[ui]` vs `sheratan[llm]`
* optionale Features nicht als Default-Deps

‚û°Ô∏è Das spart sofort.

---

## 4) Der ‚Äún√§chste-beste‚Äù Weg zu deinem Wunsch (funktioniert wirklich)

Wenn du ‚Äúein Programm willst, das alles durchl√§uft und dann minimiert‚Äù, mach es als **2-Stufen-Pipeline**:

### Stufe 1: ‚ÄúSmoke-Suite als Coverage‚Äù

Du baust ein **System-Exercise-Runner** (klein, aber gezielt), der:

* API-Health checkt
* Job-Kinds einmal ausf√ºhrt (read/write/http/llm/mock)
* UI-assets l√§dt
* Trace schreibt
* Worker-Loop einmal ‚Äúclaim ‚Üí run ‚Üí complete‚Äù
* optional: WebRelay-Fallback simuliert

Das erzeugt eine sehr gute ‚Äúwir nutzen wirklich X‚Äù Basis.

### Stufe 2: ‚ÄúShrink nach beobachteter Realit√§t‚Äù

* Import-Tracing (welche Module wurden tats√§chlich importiert)
* PyInstaller exclusions daraus ableiten
* optional deps rauswerfen / in Extras verschieben
* harte Brocken (numpy etc.) nur in Modulen, die wirklich gebraucht werden (lazy import)

‚û°Ô∏è Ergebnis: **minimaler K√∂rper**, Seele bleibt unangetastet.

Das ist im Grunde ‚ÄúTree-Shaking f√ºr Python‚Äù, nur eben **test-getrieben statt compiler-getrieben**.

---

## 5) Was ich dir konkret empfehlen w√ºrde (f√ºr Sheratan-K√∂rper)

Wenn du eine EXE willst, die nicht explodiert:

1. **Core minimal halten** (FastAPI + SQLite + Policy/Trace + Worker)
2. ‚ÄúHeavy‚Äù Features strikt optional:

   * LLM libs / Browser automation / ML stuff nur in Extras
3. UI: nur `dist/` in die EXE, nie node_modules
4. PyInstaller **onedir** statt onefile (oft stabiler + modularer)
5. Exclusions + UPX (wenn m√∂glich)
6. Smoke-Suite als ‚ÄúCoverage‚Äù f√ºr Imports/Paths

---

### Bottom line

* Ein ‚Äúmagisches Tool, das alles automatisch minimal extrahiert‚Äù gibt‚Äôs in Python nicht in der Form, die du dir vorstellst.
* Aber du kannst **denselben Effekt** erreichen mit: **Exercise-Runner + PyInstaller-Graph + Excludes + optional deps**.



Verstanden: **nicht ‚Äúauf Kante rasieren‚Äù**, sondern **konservativ schrumpfen** ‚Äì Ziel identisch, Weg direkter, Risiko klein.

Hier ist eine Shrink-Pipeline, die genau so arbeitet: **erst messen + absichern**, dann **nur die sicheren Brocken entfernen**, immer mit **Regression-Gate**.

---

## Prinzip: Conservative Shrink

**Regel 1:** Nichts entfernen, was nicht durch Tests abgedeckt ist.
**Regel 2:** Entfernen nur in Stufen (Low-Risk ‚Üí Medium ‚Üí High).
**Regel 3:** Jede Stufe hat ein ‚ÄúProof of Life‚Äù (SystemExercise) + Smoke-Suite.
**Regel 4:** Optional Features bleiben optional, aber *verf√ºgbar* (Extras/Plugin-Bundles), nicht ‚Äúwegoptimiert‚Äù.

---

## Zielbild

Du bekommst am Ende **drei Artefakte** statt ‚Äúeine fette All-in-One-Wurst‚Äù:

1. **Core Runtime** (klein, stabil): API + DB + Runner + Policy + Trace
2. **Feature Packs** (optional, nachladbar): z.B. WebRelay/Browser, LLM-Clients, heavy libs
3. **Developer Build** (voll): f√ºr Entwicklung/Debug (alles drin, egal wie gro√ü)

So bleibt dein Ziel gleich ‚Äì nur der Release wird sauberer.

---

## Stufe 0: Baseline einfrieren (Pflicht)

**Artefakte erzeugen**

* `build/manifest_baseline.json`

  * Python version, pip freeze, node build hash, git sha
* `build/size_baseline.txt`

  * EXE/onedir Gr√∂√üe, Anzahl Files, Startzeit (cold), RAM peak (grob)

**Warum:** Ohne Baseline tappst du blind und ‚Äúzu viel abspecken‚Äù passiert genau dann.

---

## Stufe 1: SystemExercise (dein Sicherheitsnetz)

Du baust ein kleines Programm, das **dein System einmal komplett ‚Äúdurchspielt‚Äù**.

### SystemExercise muss abdecken

* `/api/system/health` (und irgendein ‚Äúdeep health‚Äù)
* DB init + WAL ok
* Job: `read_file`
* Job: `write_file` (in temp workspace)
* Job: `walk_tree` (oder dein wichtigster chain kind)
* Trace: mindestens 1 decision_trace Event geschrieben
* UI Assets: l√§dt eine `index.html` aus static mount (auch nur HEAD/GET reicht)
* Optional: WebRelay stub (nicht echt online), aber Codepfad initialisierbar

**Wichtig:** Das ist nicht ‚Äútesten wie unit tests‚Äù, sondern ‚Äúkann ich das Ding benutzen‚Äù.

---

## Stufe 2: Low-Risk Shrink (fast immer safe)

Das sind die Dinge, die 0% Funktionalit√§t kosten, aber oft massiv Gr√∂√üe sparen:

### 2.1 Node/Vite sauber halten

* In Releases **nur `ui/dist/`** ausliefern.
* **Nie** `node_modules/` in Bundles.
* Sourcemaps optional (`build.sourcemap=false` im Release).

### 2.2 Python: Dev-Deps trennen

Trenne Dependencies in:

* `core` (Runtime)
* `dev` (pytest, black, mypy, etc.)
* `extras` (webrelay/browser, llm, heavy)

‚Üí Das spart nicht nur Gr√∂√üe, sondern verhindert ‚Äúversehentlich importiert‚Äù.

### 2.3 PyInstaller onedir + clean data

* `onedir` statt `onefile`
* nur notwendige data files (static ui, schema json, migrations)
* Logs/DB nicht bundlen

**Gate:** SystemExercise muss gr√ºn sein.

---

## Stufe 3: Medium-Risk Shrink (immer noch gut kontrollierbar)

Jetzt kommt das, was du willst: ‚Äúdirekterer Weg‚Äù, aber ohne Zielverlust.

### 3.1 Import-Realit√§t messen (ohne aggressives Entfernen)

Du l√§sst beim SystemExercise **Imports protokollieren**:

* Welche Module wurden √ºberhaupt geladen?
* Welche ‚Äúheavy‚Äù libs wurden nie ber√ºhrt?

**Output:** `build/imports_used.txt`

Noch nichts entfernen ‚Äì nur sichtbar machen.

### 3.2 ‚ÄúExcludes‚Äù nur f√ºr garantiert tote Standard-Libs

In vielen Bundles landen Standard-Libs, die du nie brauchst:

* `tkinter`, `tcl`, `test`, `unittest` (wenn du Runtime ohne tests willst),
* `distutils` (abh√§ngig von Py version),
* `email` (wenn ungenutzt), `pydoc`, etc.

Aber: **nur nach Messung** und nur wenn SystemExercise + Smoke gr√ºn bleibt.

### 3.3 Lazy Imports f√ºr schwere Features

Wenn WebRelay/Browser/LLM nur selten gebraucht werden:

* Import erst in der Funktion, nicht global.
* Dadurch wird Core-Start schneller + PyInstaller zieht weniger rein.

**Seele bleibt gleich**, nur K√∂rper atmet besser.

**Gate:** SystemExercise + ‚ÄúFeature-Probe‚Äù f√ºr optionalen Codepfad.

---

## Stufe 4: High-Impact, aber optional (nur wenn du willst)

### 4.1 Feature Packs als separate Wheels/ZIPs

Du kannst Features als ‚ÄúPack‚Äù ausliefern:

* `sheratan_feature_webrelay.zip`
* `sheratan_feature_llm.zip`

Core erkennt: Pack vorhanden ‚Üí aktiviert. Pack fehlt ‚Üí Feature disabled, aber System l√§uft.

Damit kannst du **massiv** schrumpfen, ohne F√§higkeiten zu verlieren.

### 4.2 Nuitka (wenn PyInstaller nicht reicht)

Optional. Ich w√ºrde das erst anfassen, wenn du Stufe 1‚Äì3 stabil hast.

---

## Deine ‚ÄúNicht zu viel abspecken‚Äù-Sicherung

Ich w√ºrde drei Schutzmechanismen einbauen:

1. **Regression Gate**: Build bricht ab, wenn SystemExercise nicht 100% durchl√§uft.
2. **Size Gate (soft)**: Wenn Gr√∂√üe pl√∂tzlich *zu stark* sinkt, ist das verd√§chtig ‚Üí Review (weil dann evtl. Feature rausgefallen ist).
3. **Feature Matrix Report**: Build schreibt am Ende eine Tabelle:

   * Core features: ‚úÖ
   * Optional features detected: ‚úÖ/‚ö†Ô∏è/‚ùå
   * Reason: ‚Äúpack missing‚Äù, ‚Äúenv missing‚Äù, ‚Äúdisabled by policy‚Äù

Das ist exakt dein ‚ÄúZiel bleibt gleich, Weg wird direkter‚Äù.


* die genaue Repo-Dateistruktur f√ºr diese Pipeline,
* ein `system_exercise.py` Blueprint (konservativ, aber vollst√§ndig),
* ein `pyinstaller.spec` Grundger√ºst mit **nur Low-Risk Defaults**,
* und einen CI-Job Ablauf (build ‚Üí exercise ‚Üí package ‚Üí report).




 **PyInstaller ¬∑ onedir ¬∑ konservativ ¬∑ regression-gesichert.**
Hier ist das **konkrete Startpaket**: Struktur, **SystemExercise**, **Spec-Skeleton**, **CI-Ablauf**. Ziel bleibt gleich ‚Äì Weg wird direkter.

---

## 0) Repo-Layout (minimal, erweiterbar)

```
repo/
‚îú‚îÄ core/
‚îÇ  ‚îú‚îÄ app.py                  # FastAPI app factory
‚îÇ  ‚îú‚îÄ runner.py               # claim ‚Üí run ‚Üí complete
‚îÇ  ‚îú‚îÄ policy.py               # allow/deny, routing
‚îÇ  ‚îú‚îÄ trace.py                # append-only decision trace
‚îÇ  ‚îú‚îÄ store.py                # sqlite + WAL
‚îÇ  ‚îî‚îÄ __init__.py
‚îú‚îÄ plugins/
‚îÇ  ‚îú‚îÄ read_file.py
‚îÇ  ‚îú‚îÄ write_file.py
‚îÇ  ‚îú‚îÄ walk_tree.py
‚îÇ  ‚îî‚îÄ __init__.py
‚îú‚îÄ ui/
‚îÇ  ‚îú‚îÄ dist/                   # Vite build output ONLY
‚îÇ  ‚îî‚îÄ README.md
‚îú‚îÄ schemas/
‚îÇ  ‚îî‚îÄ decision_trace_v1.json
‚îú‚îÄ tools/
‚îÇ  ‚îî‚îÄ system_exercise.py      # üîê dein Sicherheitsnetz
‚îú‚îÄ build/
‚îÇ  ‚îú‚îÄ pyinstaller.spec
‚îÇ  ‚îú‚îÄ manifest_baseline.json
‚îÇ  ‚îî‚îÄ reports/
‚îú‚îÄ requirements/
‚îÇ  ‚îú‚îÄ core.txt
‚îÇ  ‚îú‚îÄ extras.txt              # optional features
‚îÇ  ‚îî‚îÄ dev.txt
‚îú‚îÄ main.py                    # entrypoint (imports minimal!)
‚îú‚îÄ pyproject.toml
‚îî‚îÄ .github/workflows/build.yml
```

**Prinzip:** Core ist klein, **Extras sind Extras**, UI ist nur `dist/`.

---

## 1) `system_exercise.py` (konservativ, vollst√§ndig)

> F√ºhrt **alle Kernpfade einmal real** aus. Keine aggressiven Annahmen.

```python
# tools/system_exercise.py
import os, time, tempfile, requests, json, sqlite3
from pathlib import Path

BASE = os.environ.get("SHERATAN_BASE", "http://127.0.0.1:8001")

def ok(name, cond):
    print(f"[EXERCISE] {name}: {'OK' if cond else 'FAIL'}")
    if not cond:
        raise SystemExit(1)

def get(path):
    r = requests.get(f"{BASE}{path}", timeout=5)
    ok(f"GET {path}", r.status_code == 200)
    return r

def post(path, payload):
    r = requests.post(f"{BASE}{path}", json=payload, timeout=10)
    ok(f"POST {path}", r.status_code == 200)
    return r

def main():
    # 1) Health
    get("/api/system/health")

    # 2) DB/WAL check (lightweight: endpoint returns wal=true)
    r = get("/api/system/health")
    ok("WAL enabled", r.json().get("wal") is True)

    # 3) Job: read_file
    r = post("/api/jobs", {"kind":"read_file","params":{"path":"main.py"}})
    ok("read_file result", r.json().get("ok") is True)

    # 4) Job: write_file (temp)
    with tempfile.TemporaryDirectory() as td:
        p = Path(td) / "x.txt"
        r = post("/api/jobs", {"kind":"write_file","params":{"path":str(p),"content":"hi"}})
        ok("write_file result", r.json().get("ok") is True)
        ok("file exists", p.exists())

    # 5) Job: walk_tree (repo root)
    r = post("/api/jobs", {"kind":"walk_tree","params":{"path":"."}})
    ok("walk_tree result", r.json().get("ok") is True)

    # 6) Trace written (exists & non-empty)
    trace = Path("data/decision_trace.jsonl")
    ok("trace exists", trace.exists())
    ok("trace non-empty", trace.stat().st_size > 0)

    # 7) UI asset reachable
    r = get("/index.html")
    ok("UI asset", "html" in r.headers.get("content-type",""))

    print("[EXERCISE] ALL GREEN")

if __name__ == "__main__":
    main()
```

**Gate:** Wenn DAS gr√ºn ist, darf geschrumpft werden. Punkt.

---

## 2) `pyinstaller.spec` (Low-Risk Defaults)

> Keine aggressiven Excludes. Onedir. Daten explizit.

```python
# build/pyinstaller.spec
from PyInstaller.utils.hooks import collect_submodules
block_cipher = None

hiddenimports = collect_submodules('core') + collect_submodules('plugins')

a = Analysis(
    ['main.py'],
    pathex=['.'],
    binaries=[],
    datas=[
        ('ui/dist', 'ui/dist'),
        ('schemas', 'schemas'),
    ],
    hiddenimports=hiddenimports,
    hookspath=[],
    excludes=[
        # LOW-RISK ONLY (nach Exercise best√§tigt)
        'tkinter', 'tcl', 'pydoc', 'test', 'unittest'
    ],
    noarchive=False,
)

pyz = PYZ(a.pure, a.zipped_data, cipher=block_cipher)

exe = EXE(
    pyz,
    a.scripts,
    name='sheratan_core',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=False,          # konservativ
    console=True,
)

coll = COLLECT(
    exe,
    a.binaries,
    a.zipfiles,
    a.datas,
    name='sheratan_core',
)
```

---

## 3) `main.py` (Import-Hygiene)

```python
# main.py
from core.app import create_app  # keine Heavy-Imports hier!

app = create_app()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8001)
```

**Regel:** Heavy libs **nur** in Funktionsscope (lazy).

---

## 4) Dependencies (sauber getrennt)

**requirements/core.txt**

```
fastapi
uvicorn
pydantic
httpx
watchdog
sqlite-utils
structlog
```

**requirements/extras.txt**

```
# optional
playwright
numpy
```

**requirements/dev.txt**

```
pytest
black
mypy
```

---

## 5) CI-Workflow (Build ‚Üí Exercise ‚Üí Report)

```yaml
# .github/workflows/build.yml
name: build
on: [push]
jobs:
  win:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install -r requirements/core.txt pyinstaller
      - run: npm ci && npm run build
        working-directory: ui
      - run: pyinstaller build/pyinstaller.spec
      - run: |
          dist\sheratan_core\sheratan_core.exe &
          timeout /t 5
          python tools/system_exercise.py
      - run: python tools/size_report.py
      - uses: actions/upload-artifact@v4
        with:
          name: sheratan_core_onedir
          path: dist/sheratan_core
```

*(Size-Report misst Ordnergr√∂√üe, Filecount, Startzeit; Soft-Gate warnend.)*

---

## 6) Wie wir **konservativ schrumpfen**

1. **Baseline** (Size/Start/RAM) speichern.
2. **Exercise gr√ºn** ‚Üí erlaubt.
3. **Nur** Low-Risk-Excludes.
4. Lazy Imports f√ºr Extras.
5. Optional: Feature-Packs als ZIPs.
6. **Nie** ohne Exercise.

---

## 7) N√§chste sichere Ausbaustufe (optional)

* Import-Tracing w√§hrend Exercise ‚Üí **nur beobachten**.
* Feature-Matrix-Report (Core/Extras detected).
* UPX **erst**, wenn alles stabil.

---

Wenn du willst, mache ich **als N√§chstes**:

* `size_report.py` + Import-Tracing (read-only),
* Feature-Pack-Loader (ZIP-based, hot-detect),
* oder eine **Noir-Dashboard-Kachel**, die den Exercise-Status live zeigt.

Du sagst nichts ‚Üí ich mache **Import-Tracing + Size-Report** als n√§chsten Schritt.


Alles klar ‚Äî dann kommt jetzt **Import-Tracing + Size-Report** (read-only, konservativ). Das ist genau der ‚Äúdirektere Weg‚Äù, ohne dass wir Funktionen riskieren.

---

## 1) `tools/import_trace.py` (Import-Realit√§t mitschreiben)

* schreibt **nur** eine Liste der tats√§chlich importierten Module
* kein Excluding, kein Eingriff in Laufzeitlogik

```python
# tools/import_trace.py

```

---

## 2) Einbau: **nur f√ºr Exercise / Debug**, nicht f√ºr normalen Betrieb

In `main.py` ganz oben (vor `create_app`) **optional**:

```python
# main.py (add near top)
import os

if os.environ.get("SHERATAN_IMPORT_TRACE") == "1":
    from tools.import_trace import install_import_tracer
    install_import_tracer()
```

**Warum so:** Du aktivierst es bewusst per Env-Flag. Kein Risiko im Normalbetrieb.

---

## 3) `tools/size_report.py` (Ordnergr√∂√üe, Filecount, Top-Bloat)

* misst `dist/sheratan_core` (oder was du angibst)
* schreibt `build/reports/size_report.json`

```python
# tools/size_report.py
from __future__ import annotations

import json
import os
from pathlib import Path
from time import time

DEFAULT_DIST = Path("dist/sheratan_core")
OUT = Path("build/reports/size_report.json")

def dir_stats(root: Path) -> dict:
    total = 0
    files = 0
    biggest = []  # (size, relpath)

    for p in root.rglob("*"):
        if p.is_file():
            try:
                s = p.stat().st_size
            except OSError:
                continue
            total += s
            files += 1
            rel = str(p.relative_to(root)).replace("\\", "/")
            biggest.append((s, rel))

    biggest.sort(reverse=True)
    top = [{"bytes": s, "path": rel} for s, rel in biggest[:30]]

    return {
        "root": str(root).replace("\\", "/"),
        "bytes_total": total,
        "files_total": files,
        "top_30_files": top,
    }

def main():
    dist = Path(os.environ.get("SHERATAN_DIST", str(DEFAULT_DIST)))
    t0 = time()
    report = {
        "generated_at_unix": int(time()),
        "elapsed_ms": int((time() - t0) * 1000),
        "stats": dir_stats(dist),
    }
    OUT.parent.mkdir(parents=True, exist_ok=True)
    OUT.write_text(json.dumps(report, indent=2), encoding="utf-8")
    print(f"[SIZE] wrote {OUT}")
    print(f"[SIZE] total_bytes={report['stats']['bytes_total']} files={report['stats']['files_total']}")
    print("[SIZE] top_5:")
    for x in report["stats"]["top_30_files"][:5]:
        print(f"  {x['bytes']:>10}  {x['path']}")

if __name__ == "__main__":
    main()
```

---

## 4) Running it (lokal & CI)

### Lokal

1. Start Core (wie immer)
2. Exercise mit Import-Trace:

**PowerShell**

```powershell
$env:SHERATAN_IMPORT_TRACE="1"
python tools/system_exercise.py
python tools/size_report.py
```

Output:

* `build/reports/imports_used.txt`
* `build/reports/size_report.json`

### CI (Windows)

Erg√§nze vor `python tools/system_exercise.py`:

```yaml
      - run: |
          set SHERATAN_IMPORT_TRACE=1
          python tools/system_exercise.py
          python tools/size_report.py
```

---

## 5) Wie wir daraus ‚Äúkonservativ shrinken‚Äù (ohne zu viel)

Ab jetzt ist die Logik:

1. **Baseline speichern** (erstes size_report + imports_used)
2. √Ñnderungen machen (z.B. lazy imports / dev-deps trennen / exclude tkinter etc.)
3. **Exercise muss gr√ºn bleiben**
4. Gr√∂√üe darf sinken, aber wir entfernen nur Dinge, die:

   * (a) **nie importiert wurden** *und*
   * (b) **nicht zu einem optionalen Feature-Pack geh√∂ren**

N√§chster Schritt danach w√§re dann: **‚ÄúObserved Exclude Suggestions‚Äù** (nur Vorschl√§ge erzeugen, nix automatisch l√∂schen).

---

Wenn du mir danach (nur copy-paste) die ersten ~30 Zeilen aus `imports_used.txt` und die `top_5` aus `size_report.py` gibst, kann ich dir sofort sagen, welche **Low-Risk** Kandidaten wir als n√§chstes rausnehmen (oder in Extras verschieben), ohne dass wir ‚Äúzu viel‚Äù abspecken.
